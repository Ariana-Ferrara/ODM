{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc90ba9",
   "metadata": {},
   "source": [
    "# Movie Database - Metacritic + IMDB Integration\n",
    "\n",
    "Building database tables from Metacritic (main source) + IMDB data.  \n",
    "All MovieIDs use format: `slug-year` (e.g., `polite-society-2023`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3a856",
   "metadata": {},
   "source": [
    "# STEP 1: IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3650606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf1cdae",
   "metadata": {},
   "source": [
    "# STEP 2: LOAD DATA FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92e87cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metacritic: 1411 movies, 17869 expert reviews, 16000 user reviews\n"
     ]
    }
   ],
   "source": [
    "# Load Metacritic CSV files\n",
    "mc_movies = pd.read_csv('movies_dataMC.csv')\n",
    "mc_expert_reviews = pd.read_csv('expert_reviews_dataMC.csv')\n",
    "mc_user_reviews = pd.read_csv('user_reviews_dataMC.csv')\n",
    "\n",
    "# Remove header row if present\n",
    "mc_movies = mc_movies[mc_movies['movie_id'] != 'movie']\n",
    "\n",
    "print(f\"Metacritic: {len(mc_movies)} movies, {len(mc_expert_reviews)} expert reviews, {len(mc_user_reviews)} user reviews\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9e60db",
   "metadata": {},
   "source": [
    "# STEP 3: LOAD IMDB JSON FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8ae5603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB: 1031 movies, 6423 user reviews\n"
     ]
    }
   ],
   "source": [
    "# Load IMDB JSON file\n",
    "with open('output3.json', 'r') as file:\n",
    "    content = file.read()\n",
    "    \n",
    "# Parse JSON (handles both array format and line-by-line format)\n",
    "imdb_records = []\n",
    "try:\n",
    "    imdb_records = json.loads(content)\n",
    "except:\n",
    "    for line in content.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line and line not in ['[', ']', ',']:\n",
    "            try:\n",
    "                if line.endswith(','):\n",
    "                    line = line[:-1]\n",
    "                imdb_records.append(json.loads(line))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "imdb_df = pd.DataFrame(imdb_records)\n",
    "\n",
    "# Split movies and reviews (both are in same JSON file)\n",
    "imdb_movies = imdb_df[imdb_df['title'].notna()].copy()\n",
    "imdb_reviews = imdb_df[imdb_df['reviewer_name'].notna()].copy()\n",
    "\n",
    "print(f\"IMDB: {len(imdb_movies)} movies, {len(imdb_reviews)} user reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a520fc86",
   "metadata": {},
   "source": [
    "# STEP 4: HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd8ac44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_title(title):\n",
    "    \"\"\"Clean title for matching (lowercase, no special chars, no articles)\"\"\"\n",
    "    if pd.isna(title):\n",
    "        return \"\"\n",
    "    title = str(title).lower().strip()\n",
    "    title = re.sub(r'\\s*\\(\\d{4}\\)\\s*$', '', title)  # Remove (year)\n",
    "    title = re.sub(r'^(the|a|an)\\s+', '', title)  # Remove articles\n",
    "    title = re.sub(r'[^\\w\\s]', '', title)  # Remove special chars\n",
    "    return ' '.join(title.split())\n",
    "\n",
    "def create_slug(title):\n",
    "    \"\"\"Convert title to URL slug (polite-society)\"\"\"\n",
    "    if pd.isna(title):\n",
    "        return \"\"\n",
    "    slug = str(title).lower()\n",
    "    slug = re.sub(r'[^a-z0-9]+', '-', slug)\n",
    "    return slug.strip('-')\n",
    "\n",
    "def extract_year(date_string):\n",
    "    \"\"\"Extract 4-digit year from date string\"\"\"\n",
    "    if pd.isna(date_string):\n",
    "        return None\n",
    "    match = re.search(r'\\b(19|20)\\d{2}\\b', str(date_string))\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    \"\"\"Convert '2 h 28 m' to minutes (148)\"\"\"\n",
    "    if pd.isna(duration_str):\n",
    "        return None\n",
    "    duration_str = str(duration_str)\n",
    "    minutes = 0\n",
    "    hours_match = re.search(r'(\\d+)\\s*h', duration_str)\n",
    "    if hours_match:\n",
    "        minutes += int(hours_match.group(1)) * 60\n",
    "    mins_match = re.search(r'(\\d+)\\s*m', duration_str)\n",
    "    if mins_match:\n",
    "        minutes += int(mins_match.group(1))\n",
    "    return minutes if minutes > 0 else None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc06941",
   "metadata": {},
   "source": [
    "# STEP 5: MATCH IMDB WITH METACRITIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa8635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: 104 movies (title+year: 84, title only: 20)\n",
      "Unmatched IMDB: 927\n"
     ]
    }
   ],
   "source": [
    "# Add normalized titles and years for matching\n",
    "mc_movies['normalized_title'] = mc_movies['title'].apply(normalize_title)\n",
    "mc_movies['year'] = mc_movies['release_date'].apply(extract_year)\n",
    "\n",
    "imdb_movies['normalized_title'] = imdb_movies['title'].apply(normalize_title)\n",
    "imdb_movies['year'] = imdb_movies['release_date'].apply(extract_year)\n",
    "\n",
    "# Match by title + year\n",
    "matches_year = pd.merge(\n",
    "    imdb_movies[['movie_id', 'title', 'normalized_title', 'year']],\n",
    "    mc_movies[['movie_id', 'title', 'normalized_title', 'year']],\n",
    "    on=['normalized_title', 'year'],\n",
    "    how='inner',\n",
    "    suffixes=('_imdb', '_mc')\n",
    ")\n",
    "\n",
    "# Match by title only (for unmatched)\n",
    "unmatched_imdb = imdb_movies[~imdb_movies['movie_id'].isin(matches_year['movie_id_imdb'])]\n",
    "unmatched_mc = mc_movies[~mc_movies['movie_id'].isin(matches_year['movie_id_mc'])]\n",
    "\n",
    "matches_title = pd.merge(\n",
    "    unmatched_imdb[['movie_id', 'title', 'normalized_title']],\n",
    "    unmatched_mc[['movie_id', 'title', 'normalized_title']],\n",
    "    on='normalized_title',\n",
    "    how='inner',\n",
    "    suffixes=('_imdb', '_mc')\n",
    ")\n",
    "\n",
    "all_matches = pd.concat([matches_year, matches_title], ignore_index=True)\n",
    "\n",
    "print(f\"Matched: {len(all_matches)} movies (title+year: {len(matches_year)}, title only: {len(matches_title)})\")\n",
    "print(f\"Unmatched IMDB: {len(imdb_movies) - len(all_matches)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60015db3",
   "metadata": {},
   "source": [
    "# STEP 6: CREATE MOVIE TABLE (slug-year format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c826dbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie table: 2339 total (1411 MC + 928 IMDB)\n",
      "Mappings: mc_to_new_id (1411), imdb_to_new_id (928)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>furiosa-a-mad-max-saga-2024</td>\n",
       "      <td>Furiosa: A Mad Max Saga</td>\n",
       "      <td>May 24, 2024</td>\n",
       "      <td>metacritic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beyond-utopia-2023</td>\n",
       "      <td>Beyond Utopia</td>\n",
       "      <td>Oct 23, 2023</td>\n",
       "      <td>metacritic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chicken-for-linda!-2024</td>\n",
       "      <td>Chicken for Linda!</td>\n",
       "      <td>Apr 5, 2024</td>\n",
       "      <td>metacritic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>youth-hard-times-2024</td>\n",
       "      <td>Youth (Hard Times)</td>\n",
       "      <td>Nov 1, 2024</td>\n",
       "      <td>metacritic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>viet-and-nam-2025</td>\n",
       "      <td>Viet and Nam</td>\n",
       "      <td>Mar 28, 2025</td>\n",
       "      <td>metacritic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the-girl-with-the-needle-2024</td>\n",
       "      <td>The Girl with the Needle</td>\n",
       "      <td>Dec 6, 2024</td>\n",
       "      <td>metacritic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the-league-2023</td>\n",
       "      <td>The League</td>\n",
       "      <td>Jul 7, 2023</td>\n",
       "      <td>metacritic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>godland-2023</td>\n",
       "      <td>Godland</td>\n",
       "      <td>Feb 3, 2023</td>\n",
       "      <td>metacritic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mountains-2024</td>\n",
       "      <td>Mountains</td>\n",
       "      <td>Aug 16, 2024</td>\n",
       "      <td>metacritic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>last-summer-2023-2024</td>\n",
       "      <td>Last Summer</td>\n",
       "      <td>Jun 28, 2024</td>\n",
       "      <td>metacritic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MovieID                     title  release_date  \\\n",
       "0    furiosa-a-mad-max-saga-2024   Furiosa: A Mad Max Saga  May 24, 2024   \n",
       "1             beyond-utopia-2023             Beyond Utopia  Oct 23, 2023   \n",
       "2        chicken-for-linda!-2024        Chicken for Linda!   Apr 5, 2024   \n",
       "3          youth-hard-times-2024        Youth (Hard Times)   Nov 1, 2024   \n",
       "4              viet-and-nam-2025              Viet and Nam  Mar 28, 2025   \n",
       "5  the-girl-with-the-needle-2024  The Girl with the Needle   Dec 6, 2024   \n",
       "6                the-league-2023                The League   Jul 7, 2023   \n",
       "7                   godland-2023                   Godland   Feb 3, 2023   \n",
       "8                 mountains-2024                 Mountains  Aug 16, 2024   \n",
       "9          last-summer-2023-2024               Last Summer  Jun 28, 2024   \n",
       "\n",
       "       source  \n",
       "0  metacritic  \n",
       "1  metacritic  \n",
       "2  metacritic  \n",
       "3  metacritic  \n",
       "4  metacritic  \n",
       "5  metacritic  \n",
       "6  metacritic  \n",
       "7  metacritic  \n",
       "8  metacritic  \n",
       "9  metacritic  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process Metacritic Movies\n",
    "mc_movies['MovieID'] = mc_movies.apply(\n",
    "    lambda row: f\"{row['movie_id']}-{row['year']}\" if pd.notna(row['year']) else row['movie_id'],\n",
    "    axis=1\n",
    ")\n",
    "mc_movies['original_id'] = mc_movies['movie_id'].copy()\n",
    "\n",
    "Movie_MC = mc_movies[[\n",
    "    'MovieID', 'original_id', 'title', 'release_date', 'duration', 'rating', 'genres',\n",
    "    'production_company', 'tagline', 'website', 'awards'\n",
    "]].copy()\n",
    "Movie_MC['duration'] = Movie_MC['duration'].apply(parse_duration)\n",
    "Movie_MC['source'] = 'metacritic'\n",
    "\n",
    "# Process Unmatched IMDB Movies\n",
    "unmatched_imdb_ids = set(imdb_movies['movie_id']) - set(all_matches['movie_id_imdb'])\n",
    "unmatched_imdb_movies = imdb_movies[imdb_movies['movie_id'].isin(unmatched_imdb_ids)].copy()\n",
    "\n",
    "unmatched_imdb_movies['slug'] = unmatched_imdb_movies['title'].apply(create_slug)\n",
    "unmatched_imdb_movies['MovieID'] = unmatched_imdb_movies.apply(\n",
    "    lambda row: f\"{row['slug']}-{row['year']}\" if pd.notna(row['year']) else row['slug'],\n",
    "    axis=1\n",
    ")\n",
    "unmatched_imdb_movies['original_id'] = unmatched_imdb_movies['movie_id'].copy()\n",
    "unmatched_imdb_movies['duration'] = unmatched_imdb_movies['duration'].apply(parse_duration)\n",
    "\n",
    "Movie_IMDB = pd.DataFrame({\n",
    "    'MovieID': unmatched_imdb_movies['MovieID'],\n",
    "    'original_id': unmatched_imdb_movies['original_id'],\n",
    "    'title': unmatched_imdb_movies['title'],\n",
    "    'release_date': unmatched_imdb_movies['release_date'],\n",
    "    'duration': unmatched_imdb_movies['duration'],\n",
    "    'rating': unmatched_imdb_movies['rating'],\n",
    "    'genres': unmatched_imdb_movies['genres'],\n",
    "    'production_company': unmatched_imdb_movies['production_company'],\n",
    "    'tagline': None,\n",
    "    'website': None,\n",
    "    'awards': None,\n",
    "    'source': 'imdb'\n",
    "})\n",
    "\n",
    "# Combine\n",
    "Movie = pd.concat([Movie_MC, Movie_IMDB], ignore_index=True)\n",
    "\n",
    "# *** CRITICAL: Create mapping dictionaries for later use ***\n",
    "mc_to_new_id = dict(zip(Movie_MC['original_id'], Movie_MC['MovieID']))\n",
    "imdb_to_new_id = dict(zip(Movie_IMDB['original_id'], Movie_IMDB['MovieID']))\n",
    "\n",
    "print(f\"Movie table: {len(Movie)} total ({len(Movie_MC)} MC + {len(Movie_IMDB)} IMDB)\")\n",
    "print(f\"Mappings: mc_to_new_id ({len(mc_to_new_id)}), imdb_to_new_id ({len(imdb_to_new_id)})\")\n",
    "Movie[['MovieID', 'title', 'release_date', 'source']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc49dad",
   "metadata": {},
   "source": [
    "# STEP 7: CREATE SALES TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af71295a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales table: 928 records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Budget</th>\n",
       "      <th>GrossWorldwide</th>\n",
       "      <th>OpeningWeekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>little-dixie-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>outlast-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>duk-sit-dai-jong-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14911562.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>karate-ghost-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>pertsa-kilu-faaraon-sormus-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MovieID  Budget  GrossWorldwide  OpeningWeekend\n",
       "2                 little-dixie-2023     NaN             NaN             NaN\n",
       "23                     outlast-2023     NaN             NaN             NaN\n",
       "40            duk-sit-dai-jong-2023     NaN      14911562.0             NaN\n",
       "49                karate-ghost-2023     NaN             NaN             NaN\n",
       "56  pertsa-kilu-faaraon-sormus-2023     NaN             NaN             NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sales = imdb_movies[['movie_id', 'budget', 'grossworldwide', 'openingweekend']].copy()\n",
    "\n",
    "# Map using the dictionary from Step 6\n",
    "Sales['MovieID'] = Sales['movie_id'].map(imdb_to_new_id)\n",
    "Sales = Sales.dropna(subset=['MovieID'])\n",
    "\n",
    "# Clean currency\n",
    "for col in ['budget', 'grossworldwide', 'openingweekend']:\n",
    "    Sales[col] = Sales[col].astype(str).str.replace('[\\$,]', '', regex=True)\n",
    "    Sales[col] = pd.to_numeric(Sales[col], errors='coerce')\n",
    "\n",
    "Sales = Sales.rename(columns={\n",
    "    'budget': 'Budget',\n",
    "    'grossworldwide': 'GrossWorldwide', \n",
    "    'openingweekend': 'OpeningWeekend'\n",
    "})\n",
    "Sales = Sales[['MovieID', 'Budget', 'GrossWorldwide', 'OpeningWeekend']]\n",
    "\n",
    "# Verify no orphans\n",
    "Sales = Sales[Sales['MovieID'].isin(Movie['MovieID'])]\n",
    "\n",
    "print(f\"Sales table: {len(Sales)} records\")\n",
    "Sales.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288788e8",
   "metadata": {},
   "source": [
    "# STEP 8: CREATE PERSON TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ee58b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person table: 2953 people\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>George Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Madeleine Gavin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Sébastien Laudenbach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chiara Malta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Wang Bing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PersonID                  name\n",
       "0         1         George Miller\n",
       "1         2       Madeleine Gavin\n",
       "2         3  Sébastien Laudenbach\n",
       "3         4          Chiara Malta\n",
       "4         5             Wang Bing"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all people from directors and writers\n",
    "directors = mc_movies['director'].dropna().str.split(',').explode().str.strip()\n",
    "writers = mc_movies['writer'].dropna().str.split(',').explode().str.strip()\n",
    "\n",
    "Person = pd.DataFrame({'name': pd.concat([directors, writers]).unique()})\n",
    "Person['PersonID'] = range(1, len(Person) + 1)\n",
    "Person = Person[['PersonID', 'name']]\n",
    "\n",
    "print(f\"Person table: {len(Person)} people\")\n",
    "Person.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7ad733",
   "metadata": {},
   "source": [
    "# STEP 9: CREATE DIRECTOR TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "742c1fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Director table: 1577 relationships\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>PersonID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>furiosa-a-mad-max-saga-2024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beyond-utopia-2023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chicken-for-linda!-2024</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chicken-for-linda!-2024</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>youth-hard-times-2024</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MovieID  PersonID\n",
       "1  furiosa-a-mad-max-saga-2024         1\n",
       "2           beyond-utopia-2023         2\n",
       "3      chicken-for-linda!-2024         3\n",
       "3      chicken-for-linda!-2024         4\n",
       "4        youth-hard-times-2024         5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directors_expanded = mc_movies[['MovieID', 'director']].copy()\n",
    "directors_expanded = directors_expanded[directors_expanded['director'].notna()]\n",
    "directors_expanded = directors_expanded.assign(\n",
    "    director=directors_expanded['director'].str.split(',')\n",
    ").explode('director')\n",
    "directors_expanded['director'] = directors_expanded['director'].str.strip()\n",
    "\n",
    "person_map = dict(zip(Person['name'], Person['PersonID']))\n",
    "directors_expanded['PersonID'] = directors_expanded['director'].map(person_map)\n",
    "\n",
    "Director = directors_expanded[['MovieID', 'PersonID']].dropna()\n",
    "Director = Director.drop_duplicates()\n",
    "\n",
    "print(f\"Director table: {len(Director)} relationships\")\n",
    "Director.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbaf126",
   "metadata": {},
   "source": [
    "# STEP 10: CREATE WRITER TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22bd053a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer table: 2758 relationships\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>PersonID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>furiosa-a-mad-max-saga-2024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>furiosa-a-mad-max-saga-2024</td>\n",
       "      <td>1425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beyond-utopia-2023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chicken-for-linda!-2024</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chicken-for-linda!-2024</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MovieID  PersonID\n",
       "1  furiosa-a-mad-max-saga-2024         1\n",
       "1  furiosa-a-mad-max-saga-2024      1425\n",
       "2           beyond-utopia-2023         2\n",
       "3      chicken-for-linda!-2024         4\n",
       "3      chicken-for-linda!-2024         3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writers_expanded = mc_movies[['MovieID', 'writer']].copy()\n",
    "writers_expanded = writers_expanded[writers_expanded['writer'].notna()]\n",
    "writers_expanded = writers_expanded.assign(\n",
    "    writer=writers_expanded['writer'].str.split(',')\n",
    ").explode('writer')\n",
    "writers_expanded['writer'] = writers_expanded['writer'].str.strip()\n",
    "\n",
    "writers_expanded['PersonID'] = writers_expanded['writer'].map(person_map)\n",
    "\n",
    "Writer = writers_expanded[['MovieID', 'PersonID']].dropna()\n",
    "Writer = Writer.drop_duplicates()\n",
    "\n",
    "print(f\"Writer table: {len(Writer)} relationships\")\n",
    "Writer.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea397d",
   "metadata": {},
   "source": [
    "# STEP 11: CREATE EXPERT & EXPERTREVIEW TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe9f031c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert table: 649 experts\n",
      "ExpertReview table: 17869 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>ExpertID</th>\n",
       "      <th>meta_score</th>\n",
       "      <th>DateP</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_0</td>\n",
       "      <td>king-coal-2023</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sheldon is a coal miner’s daughter, and her br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>expert_1</td>\n",
       "      <td>king-coal-2023</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>Aug 14, 2023</td>\n",
       "      <td>In this melancholic, thoughtfully attuned cine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>expert_2</td>\n",
       "      <td>king-coal-2023</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It offers no easy answers while spinning an ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_3</td>\n",
       "      <td>king-coal-2023</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>Aug 10, 2023</td>\n",
       "      <td>Filmmaker Elaine McMillion Sheldon, a native o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expert_4</td>\n",
       "      <td>king-coal-2023</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>King Coal goes deeper into the cultural roots ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ReviewID         MovieID  ExpertID  meta_score         DateP  \\\n",
       "0  expert_0  king-coal-2023         1          91           NaN   \n",
       "1  expert_1  king-coal-2023         2          90  Aug 14, 2023   \n",
       "2  expert_2  king-coal-2023         3          83           NaN   \n",
       "3  expert_3  king-coal-2023         4          80  Aug 10, 2023   \n",
       "4  expert_4  king-coal-2023         5          75           NaN   \n",
       "\n",
       "                                             summary  \n",
       "0  Sheldon is a coal miner’s daughter, and her br...  \n",
       "1  In this melancholic, thoughtfully attuned cine...  \n",
       "2  It offers no easy answers while spinning an ev...  \n",
       "3  Filmmaker Elaine McMillion Sheldon, a native o...  \n",
       "4  King Coal goes deeper into the cultural roots ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expert table\n",
    "Expert = mc_expert_reviews[['expert_name']].drop_duplicates().copy()\n",
    "Expert['ExpertID'] = range(1, len(Expert) + 1)\n",
    "Expert = Expert.rename(columns={'expert_name': 'name'})\n",
    "Expert = Expert[['ExpertID', 'name']]\n",
    "\n",
    "print(f\"Expert table: {len(Expert)} experts\")\n",
    "\n",
    "# ExpertReview table\n",
    "ExpertReview = mc_expert_reviews.copy()\n",
    "ExpertReview['MovieID'] = ExpertReview['movie_id'].map(mc_to_new_id)\n",
    "\n",
    "expert_map = dict(zip(Expert['name'], Expert['ExpertID']))\n",
    "ExpertReview['ExpertID'] = ExpertReview['expert_name'].map(expert_map)\n",
    "ExpertReview['ReviewID'] = ['expert_' + str(i) for i in range(len(ExpertReview))]\n",
    "\n",
    "ExpertReview = ExpertReview[['ReviewID', 'MovieID', 'ExpertID', 'expert_score', 'review_date', 'review_text']]\n",
    "ExpertReview = ExpertReview.rename(columns={\n",
    "    'expert_score': 'meta_score',\n",
    "    'review_date': 'DateP',\n",
    "    'review_text': 'summary'\n",
    "})\n",
    "ExpertReview = ExpertReview[ExpertReview['MovieID'].notna()]\n",
    "\n",
    "print(f\"ExpertReview table: {len(ExpertReview)} reviews\")\n",
    "ExpertReview.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c331a422",
   "metadata": {},
   "source": [
    "# STEP 12: CREATE USER & USERREVIEW TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a9b8f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User table created: 8922 users\n",
      "Metacritic user reviews: 16000\n",
      "IMDB user reviews: 4304\n",
      "\n",
      "============================================================\n",
      "UserReview table: 20304 total reviews\n",
      "  - MC reviews: 16000\n",
      "  - IMDB reviews: 4304\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>user_score</th>\n",
       "      <th>DateP</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mc_user_0</td>\n",
       "      <td>the-rip-2026</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Jan 22, 2026</td>\n",
       "      <td>There are films that don’t try to reinvent any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mc_user_1</td>\n",
       "      <td>the-rip-2026</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Jan 21, 2026</td>\n",
       "      <td>The definition of mid, ok, \"meh\". It wasn't ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mc_user_2</td>\n",
       "      <td>the-rip-2026</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Jan 21, 2026</td>\n",
       "      <td>If you like one shootout after another, with s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mc_user_3</td>\n",
       "      <td>the-rip-2026</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Jan 21, 2026</td>\n",
       "      <td>Too many unnecessary F bombs. At best a B movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mc_user_4</td>\n",
       "      <td>the-rip-2026</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Jan 20, 2026</td>\n",
       "      <td>The Rip is a film that makes clear, from the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mc_user_5</td>\n",
       "      <td>the-rip-2026</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Jan 20, 2026</td>\n",
       "      <td>Another 4/10 Netflix movie noone asked for and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mc_user_6</td>\n",
       "      <td>the-rip-2026</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Jan 17, 2026</td>\n",
       "      <td>Damon and Affleck's little Netflix thriller is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mc_user_7</td>\n",
       "      <td>the-rip-2026</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan 19, 2026</td>\n",
       "      <td>Worst third act I have seen in some time. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mc_user_8</td>\n",
       "      <td>the-rip-2026</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>Jan 19, 2026</td>\n",
       "      <td>No decepciona, buena trama no se descubre hast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mc_user_9</td>\n",
       "      <td>the-rip-2026</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan 19, 2026</td>\n",
       "      <td>**** number of times the screenwriters typed t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ReviewID       MovieID  UserID user_score         DateP  \\\n",
       "0  mc_user_0  the-rip-2026       1          7  Jan 22, 2026   \n",
       "1  mc_user_1  the-rip-2026       2          5  Jan 21, 2026   \n",
       "2  mc_user_2  the-rip-2026       3          4  Jan 21, 2026   \n",
       "3  mc_user_3  the-rip-2026       4          6  Jan 21, 2026   \n",
       "4  mc_user_4  the-rip-2026       5          6  Jan 20, 2026   \n",
       "5  mc_user_5  the-rip-2026       6          4  Jan 20, 2026   \n",
       "6  mc_user_6  the-rip-2026       7          8  Jan 17, 2026   \n",
       "7  mc_user_7  the-rip-2026       8          1  Jan 19, 2026   \n",
       "8  mc_user_8  the-rip-2026       9          8  Jan 19, 2026   \n",
       "9  mc_user_9  the-rip-2026      10          0  Jan 19, 2026   \n",
       "\n",
       "                                             summary  \n",
       "0  There are films that don’t try to reinvent any...  \n",
       "1  The definition of mid, ok, \"meh\". It wasn't ba...  \n",
       "2  If you like one shootout after another, with s...  \n",
       "3  Too many unnecessary F bombs. At best a B movi...  \n",
       "4  The Rip is a film that makes clear, from the v...  \n",
       "5  Another 4/10 Netflix movie noone asked for and...  \n",
       "6  Damon and Affleck's little Netflix thriller is...  \n",
       "7  Worst third act I have seen in some time. The ...  \n",
       "8  No decepciona, buena trama no se descubre hast...  \n",
       "9  **** number of times the screenwriters typed t...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 1: Create User Table\n",
    "mc_users = mc_user_reviews[['user_name']].drop_duplicates().rename(columns={'user_name': 'Reviewer'})\n",
    "imdb_users = imdb_reviews[['reviewer_name']].drop_duplicates().rename(columns={'reviewer_name': 'Reviewer'})\n",
    "User = pd.concat([mc_users, imdb_users], ignore_index=True).drop_duplicates()\n",
    "User['UserID'] = range(1, len(User) + 1)\n",
    "User = User[['UserID', 'Reviewer']]\n",
    "\n",
    "print(f\"User table created: {len(User)} users\")\n",
    "\n",
    "# Part 2: Process Metacritic User Reviews\n",
    "UserReview_MC = mc_user_reviews.copy()\n",
    "UserReview_MC = UserReview_MC[UserReview_MC['movie_id'].notna()]\n",
    "UserReview_MC['MovieID'] = UserReview_MC['movie_id'].map(mc_to_new_id)\n",
    "UserReview_MC = UserReview_MC.merge(User, left_on='user_name', right_on='Reviewer', how='left')\n",
    "UserReview_MC['ReviewID'] = ['mc_user_' + str(i) for i in range(len(UserReview_MC))]\n",
    "UserReview_MC = UserReview_MC[['ReviewID', 'MovieID', 'UserID', 'user_score', 'review_date', 'review_text']]\n",
    "UserReview_MC = UserReview_MC.rename(columns={'review_date': 'DateP', 'review_text': 'summary'})\n",
    "UserReview_MC = UserReview_MC[UserReview_MC['MovieID'].notna()]\n",
    "\n",
    "print(f\"Metacritic user reviews: {len(UserReview_MC)}\")\n",
    "\n",
    "# Part 3: Process IMDB User Reviews\n",
    "UserReview_IMDB = imdb_reviews.copy()\n",
    "UserReview_IMDB = UserReview_IMDB[UserReview_IMDB['movie_id'].notna()]\n",
    "UserReview_IMDB['MovieID'] = UserReview_IMDB['movie_id'].map(imdb_to_new_id)\n",
    "UserReview_IMDB = UserReview_IMDB.merge(User, left_on='reviewer_name', right_on='Reviewer', how='left')\n",
    "UserReview_IMDB['ReviewID'] = ['imdb_user_' + str(i) for i in range(len(UserReview_IMDB))]\n",
    "UserReview_IMDB = UserReview_IMDB[['ReviewID', 'MovieID', 'UserID', 'review_score', 'review_date', 'review_text']]\n",
    "UserReview_IMDB = UserReview_IMDB.rename(columns={'review_score': 'user_score', 'review_date': 'DateP', 'review_text': 'summary'})\n",
    "UserReview_IMDB = UserReview_IMDB[UserReview_IMDB['MovieID'].notna()]\n",
    "\n",
    "print(f\"IMDB user reviews: {len(UserReview_IMDB)}\")\n",
    "\n",
    "# Part 4: Combine All Reviews\n",
    "UserReview = pd.concat([UserReview_MC, UserReview_IMDB], ignore_index=True)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"UserReview table: {len(UserReview)} total reviews\")\n",
    "print(f\"  - MC reviews: {len(UserReview_MC)}\")\n",
    "print(f\"  - IMDB reviews: {len(UserReview_IMDB)}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "UserReview.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e59ac6",
   "metadata": {},
   "source": [
    "# STEP 13: SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dfb2f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATABASE SUMMARY\n",
      "============================================================\n",
      "Movie:         2339 rows\n",
      "Sales:          928 rows\n",
      "Person:        2953 rows\n",
      "Director:      1577 rows\n",
      "Writer:        2758 rows\n",
      "Expert:         649 rows\n",
      "ExpertReview: 17869 rows\n",
      "User:          8922 rows\n",
      "UserReview:   20304 rows\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATABASE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Movie:        {len(Movie):5} rows\")\n",
    "print(f\"Sales:        {len(Sales):5} rows\")\n",
    "print(f\"Person:       {len(Person):5} rows\")\n",
    "print(f\"Director:     {len(Director):5} rows\")\n",
    "print(f\"Writer:       {len(Writer):5} rows\")\n",
    "print(f\"Expert:       {len(Expert):5} rows\")\n",
    "print(f\"ExpertReview: {len(ExpertReview):5} rows\")\n",
    "print(f\"User:         {len(User):5} rows\")\n",
    "print(f\"UserReview:   {len(UserReview):5} rows\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6148cac",
   "metadata": {},
   "source": [
    "# STEP 14: EXPORT TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da136685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Movie.csv\n",
      "✓ Sales.csv\n",
      "✓ Person.csv\n",
      "✓ Director.csv\n",
      "✓ Writer.csv\n",
      "✓ Expert.csv\n",
      "✓ ExpertReview.csv\n",
      "✓ User.csv\n",
      "✓ UserReview.csv\n",
      "\n",
      "Files saved to database_tables/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = 'database_tables'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "tables = [\n",
    "    ('Movie.csv', Movie),\n",
    "    ('Sales.csv', Sales),\n",
    "    ('Person.csv', Person),\n",
    "    ('Director.csv', Director),\n",
    "    ('Writer.csv', Writer),\n",
    "    ('Expert.csv', Expert),\n",
    "    ('ExpertReview.csv', ExpertReview),\n",
    "    ('User.csv', User),\n",
    "    ('UserReview.csv', UserReview)\n",
    "]\n",
    "\n",
    "for filename, df in tables:\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"✓ {filename}\")\n",
    "\n",
    "print(f\"\\nFiles saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f029fe1",
   "metadata": {},
   "source": [
    "# STEP 15: DATA QUALITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9b7947a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreign Key Checks:\n",
      "----------------------------------------\n",
      "Sales → Movie             success\n",
      "Director → Movie          success\n",
      "Director → Person         success\n",
      "Writer → Movie            success\n",
      "Writer → Person           success\n",
      "ExpertReview → Movie      success\n",
      "ExpertReview → Expert     success\n",
      "UserReview → Movie        success\n",
      "UserReview → User         success\n",
      "----------------------------------------\n",
      "All checks passed!\n"
     ]
    }
   ],
   "source": [
    "# Check foreign key integrity\n",
    "checks = [\n",
    "    ('Sales → Movie', Sales[~Sales['MovieID'].isin(Movie['MovieID'])]),\n",
    "    ('Director → Movie', Director[~Director['MovieID'].isin(Movie['MovieID'])]),\n",
    "    ('Director → Person', Director[~Director['PersonID'].isin(Person['PersonID'])]),\n",
    "    ('Writer → Movie', Writer[~Writer['MovieID'].isin(Movie['MovieID'])]),\n",
    "    ('Writer → Person', Writer[~Writer['PersonID'].isin(Person['PersonID'])]),\n",
    "    ('ExpertReview → Movie', ExpertReview[~ExpertReview['MovieID'].isin(Movie['MovieID'])]),\n",
    "    ('ExpertReview → Expert', ExpertReview[~ExpertReview['ExpertID'].isin(Expert['ExpertID'])]),\n",
    "    ('UserReview → Movie', UserReview[~UserReview['MovieID'].isin(Movie['MovieID'])]),\n",
    "    ('UserReview → User', UserReview[~UserReview['UserID'].isin(User['UserID'])])\n",
    "]\n",
    "\n",
    "print(\"Foreign Key Checks:\")\n",
    "print(\"-\" * 40)\n",
    "for name, invalid in checks:\n",
    "    status = \"success\" if len(invalid) == 0 else f\" {len(invalid)} errors\"\n",
    "    print(f\"{name:25} {status}\")\n",
    "\n",
    "total_errors = sum(len(invalid) for _, invalid in checks)\n",
    "print(\"-\" * 40)\n",
    "if total_errors == 0:\n",
    "    print(\"All checks passed!\")\n",
    "else:\n",
    "    print(f\" {total_errors} issues found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21852246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into SQLite database...\n",
      "============================================================\n",
      "✓ Movie: 2339 rows loaded\n",
      "✓ Sales: 928 rows loaded\n",
      "✓ User: 8922 rows loaded\n",
      "✓ UserReview: 20304 rows loaded\n",
      "✓ Expert: 649 rows loaded\n",
      "✓ ExpertReview: 17869 rows loaded\n",
      "✓ Film_Crew: 2953 rows loaded\n",
      "✓ Director: 1577 rows loaded\n",
      "✓ Writer: 2758 rows loaded\n",
      "✓ MovieCast: 0 rows (no cast data available)\n",
      "============================================================\n",
      "DATABASE LOAD COMPLETE\n",
      "============================================================\n",
      "Movie             2339 rows\n",
      "Sales              928 rows\n",
      "User              8922 rows\n",
      "UserReview       20304 rows\n",
      "Expert             649 rows\n",
      "ExpertReview     17869 rows\n",
      "Film_Crew         2953 rows\n",
      "Director          1577 rows\n",
      "Writer            2758 rows\n",
      "MovieCast            0 rows\n",
      "============================================================\n",
      "\n",
      "Database saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# STEP 16: LOAD DATA INTO SQLITE DATABASE (FIXED VERSION)\n",
    "# ==============================================================================\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "\n",
    "# Connect to database\n",
    "conn = sqlite3.connect('OnlineDM_project.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Enable Foreign Key support\n",
    "cursor.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "\n",
    "print(\"Loading data into SQLite database...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. PREPARE MOVIE TABLE\n",
    "# ==============================================================================\n",
    "\n",
    "Movie_DB = Movie.copy()\n",
    "\n",
    "# Map columns to match your database schema\n",
    "Movie_DB = Movie_DB.rename(columns={'MovieID': 'movie_id'})\n",
    "\n",
    "# Add missing columns (set to None for now)\n",
    "Movie_DB['overall_meta_score'] = None\n",
    "Movie_DB['overall_user_score'] = None\n",
    "\n",
    "# *** FIX: Convert list/array columns to strings ***\n",
    "for col in ['genres', 'production_company', 'awards']:\n",
    "    if col in Movie_DB.columns:\n",
    "        Movie_DB[col] = Movie_DB[col].apply(\n",
    "            lambda x: ', '.join(x) if isinstance(x, list) else str(x) if pd.notna(x) else None\n",
    "        )\n",
    "\n",
    "# Select only columns that exist in your schema\n",
    "Movie_DB = Movie_DB[[\n",
    "    'movie_id', 'release_date', 'title', 'production_company', \n",
    "    'duration', 'rating', 'genres', 'tagline', 'website', 'awards',\n",
    "    'overall_meta_score', 'overall_user_score'\n",
    "]].copy()  # Add .copy() to avoid issues\n",
    "\n",
    "# Load into database\n",
    "Movie_DB.to_sql('Movie', conn, if_exists='replace', index=False)\n",
    "print(f\"✓ Movie: {len(Movie_DB)} rows loaded\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. PREPARE SALES TABLE\n",
    "# ==============================================================================\n",
    "\n",
    "Sales_DB = Sales.copy()\n",
    "\n",
    "# Map columns to match your database schema\n",
    "Sales_DB = Sales_DB.rename(columns={\n",
    "    'MovieID': 'movie_id',\n",
    "    'Budget': 'budget',\n",
    "    'GrossWorldwide': 'gross_worldwide',\n",
    "    'OpeningWeekend': 'opening_weekend'\n",
    "})\n",
    "\n",
    "# Add missing columns\n",
    "Sales_DB['gross_domestic'] = None\n",
    "Sales_DB['gross_international'] = None\n",
    "\n",
    "# Select columns in correct order\n",
    "Sales_DB = Sales_DB[[\n",
    "    'movie_id', 'budget', 'gross_domestic', 'gross_international',\n",
    "    'gross_worldwide', 'opening_weekend'\n",
    "]].copy()\n",
    "\n",
    "# Load into database\n",
    "Sales_DB.to_sql('Sales', conn, if_exists='replace', index=False)\n",
    "print(f\"✓ Sales: {len(Sales_DB)} rows loaded\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. PREPARE USER TABLE\n",
    "# ==============================================================================\n",
    "\n",
    "User_DB = User.copy()\n",
    "\n",
    "# Map columns to match your database schema\n",
    "User_DB = User_DB.rename(columns={\n",
    "    'UserID': 'user_id',\n",
    "    'Reviewer': 'reviewer'\n",
    "})\n",
    "\n",
    "# Add total_reviews column (count reviews per user)\n",
    "user_review_counts = UserReview.groupby('UserID').size().reset_index(name='total_reviews')\n",
    "User_DB = User_DB.merge(user_review_counts, left_on='user_id', right_on='UserID', how='left')\n",
    "User_DB['total_reviews'] = User_DB['total_reviews'].fillna(0).astype(int)\n",
    "User_DB = User_DB.drop('UserID', axis=1, errors='ignore')\n",
    "\n",
    "# Select columns\n",
    "User_DB = User_DB[['user_id', 'reviewer', 'total_reviews']].copy()\n",
    "\n",
    "# Load into database\n",
    "User_DB.to_sql('User', conn, if_exists='replace', index=False)\n",
    "print(f\"✓ User: {len(User_DB)} rows loaded\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. PREPARE USERREVIEW TABLE\n",
    "# ==============================================================================\n",
    "\n",
    "UserReview_DB = UserReview.copy()\n",
    "\n",
    "# Map columns to match your database schema\n",
    "UserReview_DB = UserReview_DB.rename(columns={\n",
    "    'ReviewID': 'review_id',\n",
    "    'MovieID': 'movie_id',\n",
    "    'UserID': 'user_id',\n",
    "    'DateP': 'DateP'  # Already correct\n",
    "})\n",
    "\n",
    "# Ensure user_score is integer\n",
    "UserReview_DB['user_score'] = pd.to_numeric(UserReview_DB['user_score'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Select columns\n",
    "UserReview_DB = UserReview_DB[['review_id', 'movie_id', 'user_id', 'user_score', 'DateP', 'summary']].copy()\n",
    "\n",
    "# Load into database\n",
    "UserReview_DB.to_sql('UserReview', conn, if_exists='replace', index=False)\n",
    "print(f\"✓ UserReview: {len(UserReview_DB)} rows loaded\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. PREPARE EXPERT TABLE\n",
    "# ==============================================================================\n",
    "\n",
    "Expert_DB = Expert.copy()\n",
    "\n",
    "# Map columns to match your database schema\n",
    "Expert_DB = Expert_DB.rename(columns={\n",
    "    'ExpertID': 'expert_id',\n",
    "    'name': 'reviewer'\n",
    "})\n",
    "\n",
    "# Add total_reviews column (count reviews per expert)\n",
    "expert_review_counts = ExpertReview.groupby('ExpertID').size().reset_index(name='total_reviews')\n",
    "Expert_DB = Expert_DB.merge(expert_review_counts, left_on='expert_id', right_on='ExpertID', how='left')\n",
    "Expert_DB['total_reviews'] = Expert_DB['total_reviews'].fillna(0).astype(int)\n",
    "Expert_DB = Expert_DB.drop('ExpertID', axis=1, errors='ignore')\n",
    "\n",
    "# Select columns\n",
    "Expert_DB = Expert_DB[['expert_id', 'reviewer', 'total_reviews']].copy()\n",
    "\n",
    "# Load into database\n",
    "Expert_DB.to_sql('Expert', conn, if_exists='replace', index=False)\n",
    "print(f\"✓ Expert: {len(Expert_DB)} rows loaded\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. PREPARE EXPERTREVIEW TABLE\n",
    "# ==============================================================================\n",
    "\n",
    "ExpertReview_DB = ExpertReview.copy()\n",
    "\n",
    "# Map columns to match your database schema\n",
    "ExpertReview_DB = ExpertReview_DB.rename(columns={\n",
    "    'ReviewID': 'review_id',\n",
    "    'MovieID': 'movie_id',\n",
    "    'ExpertID': 'expert_id',\n",
    "    'DateP': 'DateP'  # Already correct\n",
    "})\n",
    "\n",
    "# Ensure meta_score is integer\n",
    "ExpertReview_DB['meta_score'] = pd.to_numeric(ExpertReview_DB['meta_score'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Select columns\n",
    "ExpertReview_DB = ExpertReview_DB[['review_id', 'movie_id', 'expert_id', 'meta_score', 'DateP', 'summary']].copy()\n",
    "\n",
    "# Load into database\n",
    "ExpertReview_DB.to_sql('ExpertReview', conn, if_exists='replace', index=False)\n",
    "print(f\"✓ ExpertReview: {len(ExpertReview_DB)} rows loaded\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 7. PREPARE FILM_CREW TABLE (renamed from Person)\n",
    "# ==============================================================================\n",
    "\n",
    "FilmCrew_DB = Person.copy()\n",
    "\n",
    "# Map columns to match your database schema\n",
    "FilmCrew_DB = FilmCrew_DB.rename(columns={\n",
    "    'PersonID': 'person_id',\n",
    "    'name': 'FullName'\n",
    "})\n",
    "\n",
    "# Select columns\n",
    "FilmCrew_DB = FilmCrew_DB[['person_id', 'FullName']].copy()\n",
    "\n",
    "# Load into database\n",
    "FilmCrew_DB.to_sql('Film_Crew', conn, if_exists='replace', index=False)\n",
    "print(f\"✓ Film_Crew: {len(FilmCrew_DB)} rows loaded\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 8. PREPARE DIRECTOR TABLE\n",
    "# ==============================================================================\n",
    "\n",
    "Director_DB = Director.copy()\n",
    "\n",
    "# Map columns to match your database schema\n",
    "Director_DB = Director_DB.rename(columns={\n",
    "    'MovieID': 'movie_id',\n",
    "    'PersonID': 'person_id'\n",
    "})\n",
    "\n",
    "# Select columns\n",
    "Director_DB = Director_DB[['movie_id', 'person_id']].copy()\n",
    "\n",
    "# Load into database\n",
    "Director_DB.to_sql('Director', conn, if_exists='replace', index=False)\n",
    "print(f\"✓ Director: {len(Director_DB)} rows loaded\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 9. PREPARE WRITER TABLE\n",
    "# ==============================================================================\n",
    "\n",
    "Writer_DB = Writer.copy()\n",
    "\n",
    "# Map columns to match your database schema\n",
    "Writer_DB = Writer_DB.rename(columns={\n",
    "    'MovieID': 'movie_id',\n",
    "    'PersonID': 'person_id'\n",
    "})\n",
    "\n",
    "# Select columns\n",
    "Writer_DB = Writer_DB[['movie_id', 'person_id']].copy()\n",
    "\n",
    "# Load into database\n",
    "Writer_DB.to_sql('Writer', conn, if_exists='replace', index=False)\n",
    "print(f\"✓ Writer: {len(Writer_DB)} rows loaded\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 10. NOTE: MovieCast table is empty (no cast data in source files)\n",
    "# ==============================================================================\n",
    "\n",
    "# Create empty MovieCast table\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS MovieCast (\n",
    "        movie_id TEXT,\n",
    "        person_id INTEGER,\n",
    "        CharacterName TEXT,\n",
    "        PRIMARY KEY (movie_id, person_id),\n",
    "        FOREIGN KEY (movie_id) REFERENCES Movie (movie_id),\n",
    "        FOREIGN KEY (person_id) REFERENCES Film_crew (person_id)\n",
    "    )\n",
    "''')\n",
    "print(\"✓ MovieCast: 0 rows (no cast data available)\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATABASE LOAD COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verify counts\n",
    "tables = ['Movie', 'Sales', 'User', 'UserReview', 'Expert', 'ExpertReview', \n",
    "          'Film_Crew', 'Director', 'Writer', 'MovieCast']\n",
    "\n",
    "for table in tables:\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "    count = cursor.fetchone()[0]\n",
    "    print(f\"{table:15} {count:6} rows\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Commit and close\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nDatabase saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ODM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
